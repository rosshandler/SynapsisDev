#modelling data
lam <- c(500, 1050)
set.seed(1234)
Z = rbinom(500, 1, 0.6)
D <- rpois(1000000, lam[Z+1])
#hist(X)

#compute log-likelihood     
#w(i) = P(z(i) = j|x(i);lam, pi)
compute.log.lik <- function(D, w, mean) {
  
  w <- as.numeric(unlist(w))
  #using L from the global environment 
  L[,1] = dpois(D, mean[1], log = TRUE)
  L[,2] = dpois(D, mean[2], log = TRUE)
  
  L[,1] = L[,1]*w[1]
  L[,2] = L[,2]*w[2]
  return(sum(log(rowSums(L))))
}

#generating likelihood matrix L
L = matrix(NA, nrow=length(D), ncol= 2)


#generating EM function 
mixture.EM <- function(lam.init ,w.init, L, D) { 
  if (length(lam.init) != 2) {
    stop("lam.init must be a vector of length 2")
  }
  
  #initialising
  w.curr <- w.init
  lam.curr <- lam.init
  D <- as.numeric(D)
  L[,1] <- dpois(D, lam.init[1], log = TRUE)
 
  L[,2] <- dpois(D, lam.init[2], log = TRUE)
 

  # store log-likehoods for each iteration
  log_liks <- c()
  ll       <- compute.log.lik(D, w.curr, lam.curr)
  log_liks <- c(log_liks, ll)
  delta.ll <- 1

  while(delta.ll > 1e-5 & delta.ll != "NaN") {
    out   <- EM.iter(w.curr, L, D)
    ll       <- compute.log.lik(D, out$w.next, out$lam.next)
    log_liks <- c(log_liks, ll)
    delta.ll <- log_liks[length(log_liks)]  - log_liks[length(log_liks)-1]
  }
  
  out <- EM.iter(w.curr, L, D)
  w.curr <- out$w.next
  posteriors <- out$z_ik
  lam.curr <- out$lam.next
  
  return(list(w.curr, log_liks, posteriors, lam.init, lam.curr))
}

EM.iter <- function(w.curr, L, D, ...) {
  
  # E-step: compute E_{Z|X,w0}[I(Z_i = k)] (posteriors)
  z_ik <- L
  w.curr <- as.numeric(unlist(w.curr))
  for(i in seq_len(ncol(L))) {
    z_ik[,i] <- w.curr[i]*z_ik[,i]
  }
  z_ik     <- z_ik / rowSums(z_ik)
 
  
  # M-step
  w.next   <- colSums(z_ik)/sum(z_ik)
  lam.one <- sum(D*z_ik[,1])/sum(z_ik[,1])
  lam.two <- sum(D*z_ik[,2])/sum(z_ik[,2])
  lam.next <- c(lam.one, lam.two)
  out <- list(w.next, z_ik, lam.next)
  names(out) <- c("w.next", "z_ik", "lam.next")
  return(out)
}

##############testing#####################
#real:  500, 1050
ee <- mixture.EM(lam.init = c(100, 500), w.init=c(0.5,0.5), L, D)
ee[5] 
result: 815.6992 1023.0535

#real: 500, 1050
ee <- mixture.EM(lam.init = c(400,900), w.init=c(0.5,0.5), L, D)
results: 1005.6979  537.9321

#real: 500, 1050
ee <- mixture.EM(lam.init = c(10, 1000), w.init=c(0.5,0.5), L, D)
ee[5] 
result:846.5213 510.4158

#real: 500, 1050
ee <- mixture.EM(lam.init = c(450, 1000), w.init=c(0.5,0.5), L, D)
ee[5] 
result: 1034.1380  516.9844

#the better the mean estimates the better the result. 



############runinign the EM################

metadata <- read.csv('/data2/hanna/synaptogenesis/newvolume/analysis/metadata_alt.csv')
D <- metadata$tscp_count
L = matrix(NA, nrow=length(D), ncol= 2)

#estimating means 
h_fraction <- metadata$tscp_count[metadata$cell_species == 'h']
m_fraction <- metadata$tscp_count[metadata$cell_species == 'm']

length(h_fraction)
[1] 54149
length(m_fraction)
[1] 16303
length(m_fraction)+length(h_fraction)
[1] 70452
length(D)
[1] 70452

lam <- c()
lam[1] <- mean(h_fraction)
lam[2] <- mean(m_fraction)

lam
[1] 5077.281 6497.055

ee <- mixture.EM(lam.init = lam, w.init=c(0.5,0.5), L, D)
write.csv(ee, "EM_output_combined.csv")
write.csv(ee[3], "posteriors.csv")

ee[1] 
0.425425481269943..0.574574518730057

ee[2]
Na Na

ee[4] 
5077.281 6497.055

ee[5]
6661.947 4475.769 

posteriors < - ee[[3]]
colnames(posteriors) <- ee[5]
rownames(posteriors) <- metadata$bc_wells
posteriors <- cbind(posteriors, rep(NA, nrow(posteriors)))
colnames(posteriors)[3] <- "species" 

colnames(posteriors) <- c("m","h", "species")
for (i in 1:nrow(posteriors)){
  if (posteriors[i,1] > 0.5){
    posteriors[i,3] <- "m"}
  else {posteriors[i,3] <- "h"
  }
}

write.csv(posteriors, "posteriors.csv")

H_cells <- posteriors[posteriors[,3]=="h",]
M_cells <- posteriors[posteriors[,3]=="m",]

dim(M_cells)
[1] 10909     4
dim(H_cells)
[1] 59543     4
59543 + 10909 = 70452

metadata$species <- posteriors[,3]
write.csv(metadata, "metadata_alt.csv")

















